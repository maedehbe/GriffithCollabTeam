Important Address:  https://faculty.cc.gatech.edu/~judy/  ,, https://www.youtube.com/watch?v=AB39bb2_Vtw&list=PLT6XqV0BKKrLEXxUqW7k88pldpdYV1ldF&index=2
https://paperswithcode.com/task/adversarial-attack


Time Plan = 

Datasets = 

Methodology = 

Train = 

Test =

Evaluation =

Visualization =

Adversarial Attack Type = FGSM (attack) 
Defence = 

Result Expectations = 

Code = 

Other papers Codes =

Image is target? or Label? (targeted or non-targeted) or both =

Journal Types that we go , look for datasets

robustness of the model

layers of CNN model

Attack the model at the inference time or Training Time (you can use the system as Malicous system)
d(x,x*)<=B
Iterative attack could help PGD
How is our strategy for defence??
transferability of attack??
Train on N-1 is better than 1

Ensemble, is good for non targeted

unknown Label, Training Set and Model Architecture (backdor) are the most important for misleading the AD Attack

change the image by replacing all parts by new image, or by replacing some parts like mouth 

generalization problem is important, one model might work well for one dataset and not work for the others 

How much purturb is needed before getting start to misclassifying one perticular image?

Supervised or semi-supervised
